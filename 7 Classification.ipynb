{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification\n",
    "\n",
    "Using Classification, we will try to predict whether an observation belongs to the Responsive or Non-Responsive group. We will try a Logistic Regression model to do the classification, and if needed a Random Forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/anaconda2/lib/python2.7/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HHKEY</th>\n",
       "      <th>ZIP_CODE</th>\n",
       "      <th>REC</th>\n",
       "      <th>FRE</th>\n",
       "      <th>MON</th>\n",
       "      <th>CC_CARD</th>\n",
       "      <th>AVRG</th>\n",
       "      <th>PC_CALC20</th>\n",
       "      <th>PSWEATERS</th>\n",
       "      <th>PKNIT_TOPS</th>\n",
       "      <th>...</th>\n",
       "      <th>VALPHON</th>\n",
       "      <th>WEB</th>\n",
       "      <th>MAILED</th>\n",
       "      <th>RESPONDED</th>\n",
       "      <th>RESPONSERATE</th>\n",
       "      <th>HI</th>\n",
       "      <th>LTFREDAY</th>\n",
       "      <th>CLUSTYPE</th>\n",
       "      <th>PERCRET</th>\n",
       "      <th>RESP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9955600066402</td>\n",
       "      <td>1001</td>\n",
       "      <td>208</td>\n",
       "      <td>2</td>\n",
       "      <td>368.46</td>\n",
       "      <td>0</td>\n",
       "      <td>184.23</td>\n",
       "      <td>11</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>31.81</td>\n",
       "      <td>111.00</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9955600073501</td>\n",
       "      <td>1028</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>258.00</td>\n",
       "      <td>1</td>\n",
       "      <td>64.50</td>\n",
       "      <td>11</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.16</td>\n",
       "      <td>...</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>50.00</td>\n",
       "      <td>32.72</td>\n",
       "      <td>43.50</td>\n",
       "      <td>10</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9955600076313</td>\n",
       "      <td>1056</td>\n",
       "      <td>327</td>\n",
       "      <td>2</td>\n",
       "      <td>77.00</td>\n",
       "      <td>0</td>\n",
       "      <td>38.50</td>\n",
       "      <td>11</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>68.60</td>\n",
       "      <td>16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9955600078045</td>\n",
       "      <td>1118</td>\n",
       "      <td>66</td>\n",
       "      <td>8</td>\n",
       "      <td>846.06</td>\n",
       "      <td>1</td>\n",
       "      <td>105.75</td>\n",
       "      <td>11</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>66.67</td>\n",
       "      <td>23.27</td>\n",
       "      <td>26.96</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9955600078517</td>\n",
       "      <td>1107</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>87.44</td>\n",
       "      <td>0</td>\n",
       "      <td>87.44</td>\n",
       "      <td>11</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>28.52</td>\n",
       "      <td>24.50</td>\n",
       "      <td>20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           HHKEY  ZIP_CODE  REC  FRE     MON  CC_CARD    AVRG  PC_CALC20  \\\n",
       "0  9955600066402      1001  208    2  368.46        0  184.23         11   \n",
       "1  9955600073501      1028    6    4  258.00        1   64.50         11   \n",
       "2  9955600076313      1056  327    2   77.00        0   38.50         11   \n",
       "3  9955600078045      1118   66    8  846.06        1  105.75         11   \n",
       "4  9955600078517      1107   49    1   87.44        0   87.44         11   \n",
       "\n",
       "   PSWEATERS  PKNIT_TOPS  ...   VALPHON  WEB  MAILED  RESPONDED  RESPONSERATE  \\\n",
       "0       0.18        0.00  ...         N    0       5          0          0.00   \n",
       "1       0.26        0.16  ...         Y    0       4          2         50.00   \n",
       "2       1.00        0.00  ...         N    0       4          0          0.00   \n",
       "3       0.38        0.00  ...         Y    0       9          6         66.67   \n",
       "4       0.20        0.20  ...         Y    0       0          0          0.00   \n",
       "\n",
       "       HI  LTFREDAY  CLUSTYPE  PERCRET  RESP  \n",
       "0   31.81    111.00        10     0.00     0  \n",
       "1   32.72     43.50        10     0.03     1  \n",
       "2  100.00     68.60        16     0.00     0  \n",
       "3   23.27     26.96        10     0.00     0  \n",
       "4   28.52     24.50        20     0.00     0  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the data file\n",
    "clothingFile = pd.read_table('Clothing_Store',sep=',')\n",
    "clothingFile.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataframe for input to Logistic Regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column Descriptions\n",
    "\n",
    "- 'HHKEY' - Customer ID: unique, encrypted customer identification\n",
    "- 'ZIP_CODE' - Zip code\n",
    "- 'REC' - a variable showing the brand of choice (encrypted)\n",
    "- 'FRE' - Number of purchase visits\n",
    "- 'MON' - Total net sales\n",
    "- 'CC_CARD' - Flag: credit card user\n",
    "- 'AVRG' - Average amount spent per visit\n",
    "- 'PC_CALC20',\n",
    "- 'PSWEATERS' - percentages spent by the customer on Sweaters\n",
    "- 'PKNIT_TOPS' - percentages spent by the customer on knit tops\n",
    "- 'PKNIT_DRES' - percentages spent by the customer on knit dresses\n",
    "- 'PBLOUSES' - percentages spent by the customer on blouses\n",
    "- 'PJACKETS' - percentages spent by the customer on jackets\n",
    "- 'PCAR_PNTS' - percentages spent by the customer on career pants\n",
    "- 'PCAS_PNTS' - percentages spent by the customer on casual pants\n",
    "- 'PSHIRTS' - percentages spent by the customer on shirts\n",
    "- 'PDRESSES' - percentages spent by the customer on dresses\n",
    "- 'PSUITS' - percentages spent by the customer on suits\n",
    "- 'POUTERWEAR' - percentages spent by the customer on outerwear\n",
    "- 'PJEWELRY' - percentages spent by the customer on jewelry\n",
    "- 'PFASHION' - percentages spent by the customer on fashion\n",
    "- 'PLEGWEAR' - percentages spent by the customer on legwear\n",
    "- 'PCOLLSPND' - percentages spent by the customer on collectibles line\n",
    "- 'AMSPEND' - Spending at the AM store\n",
    "- 'PSSPEND' - Spending at the PS store\n",
    "- 'CCSPEND' - Spending at the CC store\n",
    "- 'AXSPEND' - Spending at the AX store\n",
    "- 'TMONSPEND' - Amount spent in the past three months\n",
    "- 'OMONSPEND' - Amount spent in the past month\n",
    "- 'SMONSPEND' - Amount spent in the past six months\n",
    "- 'PREVPD',\n",
    "- 'GMP' - Gross margin percentage\n",
    "- 'PROMOS' - Number of marketing promotions on file\n",
    "- 'DAYS' - Number of days the customer has been on file\n",
    "- 'FREDAYS' - Number of days between purchases\n",
    "- 'MARKDOWN' - Markdown percentage on customer purchases - indicates which customers have purchased merchandise that has been marked down\n",
    "- 'CLASSES' - Number of different product classes purchased\n",
    "- 'COUPONS' - Number of coupons used by the customer\n",
    "- 'STYLES' - Total number of individual items purchased by the customer\n",
    "- 'STORES' - Number of stores the customer shopped at\n",
    "- 'STORELOY' - Spending in the same period last year (?)\n",
    "- 'VALPHON' - Flag: valid phone number on file\n",
    "- 'WEB' - Flag: Web shopper\n",
    "- 'MAILED' - Number of promotions mailed in the past year\n",
    "- 'RESPONDED' - Number of promotions responded to in the past year\n",
    "- 'RESPONSERATE' - Promotion response rate for the past year - indicates which customers have ever responded to a marketing promotion before\n",
    "- 'HI' - Product uniformity (low score = diverse spending patterns)\n",
    "- 'LTFREDAY' - Lifetime average time between visits\n",
    "- 'CLUSTYPE' - Microvision lifestyle cluster type\n",
    "- 'PERCRET' - Percent of returns\n",
    "- 'RESP' - Target variable: response to promotion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical Columns: CC_Card, VALPHON, WEB, CLUSTYPE, RESP\n",
    "\n",
    "Column with Unique Values: HHKEY\n",
    "\n",
    "Categorical columns need to be in 0/1 format. Categorical columns with more than one category need to be flattened out so they can also have 0/1 format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HHKEY</th>\n",
       "      <th>ZIP_CODE</th>\n",
       "      <th>REC</th>\n",
       "      <th>FRE</th>\n",
       "      <th>MON</th>\n",
       "      <th>CC_CARD</th>\n",
       "      <th>AVRG</th>\n",
       "      <th>PC_CALC20</th>\n",
       "      <th>PSWEATERS</th>\n",
       "      <th>PKNIT_TOPS</th>\n",
       "      <th>...</th>\n",
       "      <th>VALPHON</th>\n",
       "      <th>WEB</th>\n",
       "      <th>MAILED</th>\n",
       "      <th>RESPONDED</th>\n",
       "      <th>RESPONSERATE</th>\n",
       "      <th>HI</th>\n",
       "      <th>LTFREDAY</th>\n",
       "      <th>CLUSTYPE</th>\n",
       "      <th>PERCRET</th>\n",
       "      <th>RESP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9955600066402</td>\n",
       "      <td>1001</td>\n",
       "      <td>208</td>\n",
       "      <td>2</td>\n",
       "      <td>368.46</td>\n",
       "      <td>0</td>\n",
       "      <td>184.23</td>\n",
       "      <td>11</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>31.81</td>\n",
       "      <td>111.00</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9955600073501</td>\n",
       "      <td>1028</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>258.00</td>\n",
       "      <td>1</td>\n",
       "      <td>64.50</td>\n",
       "      <td>11</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.16</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>50.00</td>\n",
       "      <td>32.72</td>\n",
       "      <td>43.50</td>\n",
       "      <td>10</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9955600076313</td>\n",
       "      <td>1056</td>\n",
       "      <td>327</td>\n",
       "      <td>2</td>\n",
       "      <td>77.00</td>\n",
       "      <td>0</td>\n",
       "      <td>38.50</td>\n",
       "      <td>11</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>68.60</td>\n",
       "      <td>16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9955600078045</td>\n",
       "      <td>1118</td>\n",
       "      <td>66</td>\n",
       "      <td>8</td>\n",
       "      <td>846.06</td>\n",
       "      <td>1</td>\n",
       "      <td>105.75</td>\n",
       "      <td>11</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>66.67</td>\n",
       "      <td>23.27</td>\n",
       "      <td>26.96</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9955600078517</td>\n",
       "      <td>1107</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>87.44</td>\n",
       "      <td>0</td>\n",
       "      <td>87.44</td>\n",
       "      <td>11</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>28.52</td>\n",
       "      <td>24.50</td>\n",
       "      <td>20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           HHKEY  ZIP_CODE  REC  FRE     MON  CC_CARD    AVRG  PC_CALC20  \\\n",
       "0  9955600066402      1001  208    2  368.46        0  184.23         11   \n",
       "1  9955600073501      1028    6    4  258.00        1   64.50         11   \n",
       "2  9955600076313      1056  327    2   77.00        0   38.50         11   \n",
       "3  9955600078045      1118   66    8  846.06        1  105.75         11   \n",
       "4  9955600078517      1107   49    1   87.44        0   87.44         11   \n",
       "\n",
       "   PSWEATERS  PKNIT_TOPS  ...   VALPHON  WEB  MAILED  RESPONDED  RESPONSERATE  \\\n",
       "0       0.18        0.00  ...         0    0       5          0          0.00   \n",
       "1       0.26        0.16  ...         1    0       4          2         50.00   \n",
       "2       1.00        0.00  ...         0    0       4          0          0.00   \n",
       "3       0.38        0.00  ...         1    0       9          6         66.67   \n",
       "4       0.20        0.20  ...         1    0       0          0          0.00   \n",
       "\n",
       "       HI  LTFREDAY  CLUSTYPE  PERCRET  RESP  \n",
       "0   31.81    111.00        10     0.00     0  \n",
       "1   32.72     43.50        10     0.03     1  \n",
       "2  100.00     68.60        16     0.00     0  \n",
       "3   23.27     26.96        10     0.00     0  \n",
       "4   28.52     24.50        20     0.00     0  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change VALPHON to 0 and 1 instead of N and Y\n",
    "clothingFile.VALPHON.replace(('Y', 'N'), (1, 0), inplace=True)\n",
    "clothingFile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make CLUSTYPE separate columns of 0 and 1.\n",
    "clothingFileLR = pd.get_dummies(clothingFile,columns=['CLUSTYPE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21740, 101)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HHKEY</th>\n",
       "      <th>ZIP_CODE</th>\n",
       "      <th>REC</th>\n",
       "      <th>FRE</th>\n",
       "      <th>MON</th>\n",
       "      <th>CC_CARD</th>\n",
       "      <th>AVRG</th>\n",
       "      <th>PC_CALC20</th>\n",
       "      <th>PSWEATERS</th>\n",
       "      <th>PKNIT_TOPS</th>\n",
       "      <th>...</th>\n",
       "      <th>CLUSTYPE_41</th>\n",
       "      <th>CLUSTYPE_42</th>\n",
       "      <th>CLUSTYPE_43</th>\n",
       "      <th>CLUSTYPE_44</th>\n",
       "      <th>CLUSTYPE_45</th>\n",
       "      <th>CLUSTYPE_46</th>\n",
       "      <th>CLUSTYPE_47</th>\n",
       "      <th>CLUSTYPE_48</th>\n",
       "      <th>CLUSTYPE_49</th>\n",
       "      <th>CLUSTYPE_50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9955600066402</td>\n",
       "      <td>1001</td>\n",
       "      <td>208</td>\n",
       "      <td>2</td>\n",
       "      <td>368.46</td>\n",
       "      <td>0</td>\n",
       "      <td>184.23</td>\n",
       "      <td>11</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9955600073501</td>\n",
       "      <td>1028</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>258.00</td>\n",
       "      <td>1</td>\n",
       "      <td>64.50</td>\n",
       "      <td>11</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9955600076313</td>\n",
       "      <td>1056</td>\n",
       "      <td>327</td>\n",
       "      <td>2</td>\n",
       "      <td>77.00</td>\n",
       "      <td>0</td>\n",
       "      <td>38.50</td>\n",
       "      <td>11</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9955600078045</td>\n",
       "      <td>1118</td>\n",
       "      <td>66</td>\n",
       "      <td>8</td>\n",
       "      <td>846.06</td>\n",
       "      <td>1</td>\n",
       "      <td>105.75</td>\n",
       "      <td>11</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9955600078517</td>\n",
       "      <td>1107</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>87.44</td>\n",
       "      <td>0</td>\n",
       "      <td>87.44</td>\n",
       "      <td>11</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           HHKEY  ZIP_CODE  REC  FRE     MON  CC_CARD    AVRG  PC_CALC20  \\\n",
       "0  9955600066402      1001  208    2  368.46        0  184.23         11   \n",
       "1  9955600073501      1028    6    4  258.00        1   64.50         11   \n",
       "2  9955600076313      1056  327    2   77.00        0   38.50         11   \n",
       "3  9955600078045      1118   66    8  846.06        1  105.75         11   \n",
       "4  9955600078517      1107   49    1   87.44        0   87.44         11   \n",
       "\n",
       "   PSWEATERS  PKNIT_TOPS     ...       CLUSTYPE_41  CLUSTYPE_42  CLUSTYPE_43  \\\n",
       "0       0.18        0.00     ...                 0            0            0   \n",
       "1       0.26        0.16     ...                 0            0            0   \n",
       "2       1.00        0.00     ...                 0            0            0   \n",
       "3       0.38        0.00     ...                 0            0            0   \n",
       "4       0.20        0.20     ...                 0            0            0   \n",
       "\n",
       "   CLUSTYPE_44  CLUSTYPE_45  CLUSTYPE_46  CLUSTYPE_47  CLUSTYPE_48  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   CLUSTYPE_49  CLUSTYPE_50  \n",
       "0            0            0  \n",
       "1            0            0  \n",
       "2            0            0  \n",
       "3            0            0  \n",
       "4            0            0  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(clothingFileLR.shape)\n",
    "clothingFileLR.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove Customer ID dimension - Unique values\n",
    "clothingFileLR.drop(['HHKEY'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove Target Variable\n",
    "clothingFileLRnoRESP = clothingFileLR.drop(['RESP'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Test Datasets\n",
    "\n",
    "When fitting models, we want to ensure...\n",
    "- We have found the best parameters for our model, and therefore, the best model.\n",
    "- The model is highly likely to predict well on unseen data.\n",
    "\n",
    "To do this, we will split the data into a training set and a test set. We will train the model on the training set and test the model's accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('X: ', <type 'numpy.ndarray'>, (21740, 99))\n"
     ]
    }
   ],
   "source": [
    "# Create the first parameter of train_test_split - a matrix\n",
    "columnNames = list(clothingFileLRnoRESP)\n",
    "X = clothingFileLRnoRESP[columnNames].values\n",
    "print(\"X: \", type(X), X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('y: ', <type 'numpy.ndarray'>, (21740, 1))\n"
     ]
    }
   ],
   "source": [
    "# Create the second parameter - each customers' response to the promotion\n",
    "y = clothingFileLR[['RESP']].values\n",
    "print(\"y: \", type(y), y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X and y have the following relationships...\n",
    "\n",
    "1. They have the same number of rows\n",
    "2. For a given row i of matrix X, the label that corresponds to that data point is exactly the value of vector y at that row\n",
    "3. The number of rows of X is the number of data points in the dataset\n",
    "4. The number of columns of X is the number of features of each data point in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the data into a training set and a test set\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y,random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "('Xtrain:', array([[  7.86410000e+04,   1.17000000e+02,   3.00000000e+00, ...,\n",
      "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
      "       [  7.87090000e+04,   1.60000000e+01,   3.00000000e+00, ...,\n",
      "          0.00000000e+00,   0.00000000e+00,   1.00000000e+00],\n",
      "       [  4.41460000e+04,   8.00000000e+00,   1.60000000e+01, ...,\n",
      "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
      "       ..., \n",
      "       [  9.17920000e+04,   3.45000000e+02,   1.00000000e+00, ...,\n",
      "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
      "       [  7.70840000e+04,   5.80000000e+01,   7.00000000e+00, ...,\n",
      "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
      "       [  2.08540000e+04,   2.90000000e+01,   1.00000000e+01, ...,\n",
      "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00]]), <type 'numpy.ndarray'>, (16305, 99), 16305)\n",
      "\n",
      "\n",
      "('Xtest', array([[  9.00370000e+04,   3.50000000e+01,   2.00000000e+00, ...,\n",
      "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
      "       [  7.12700000e+04,   1.57000000e+02,   4.00000000e+00, ...,\n",
      "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
      "       [  6.00500000e+04,   1.76000000e+02,   1.00000000e+00, ...,\n",
      "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
      "       ..., \n",
      "       [  7.22050000e+04,   9.60000000e+01,   1.00000000e+00, ...,\n",
      "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
      "       [  6.01260000e+04,   2.50000000e+01,   2.00000000e+00, ...,\n",
      "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
      "       [  6.01530000e+04,   2.60000000e+02,   1.00000000e+00, ...,\n",
      "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00]]), <type 'numpy.ndarray'>, (5435, 99), 5435)\n",
      "\n",
      "\n",
      "('ytrain', array([[0],\n",
      "       [0],\n",
      "       [1],\n",
      "       ..., \n",
      "       [0],\n",
      "       [0],\n",
      "       [0]]), <type 'numpy.ndarray'>, (16305, 1), 16305)\n",
      "\n",
      "\n",
      "('ytest', array([[0],\n",
      "       [0],\n",
      "       [0],\n",
      "       ..., \n",
      "       [0],\n",
      "       [0],\n",
      "       [0]]), <type 'numpy.ndarray'>, (5435, 1), 5435)\n"
     ]
    }
   ],
   "source": [
    "#By default train_test_split splits to 75% train and 25% test\n",
    "#Setting the Random State to a fixed number will guarantee that the output of Run 1 will be equal to the output\n",
    "#of Run 2, i.e. your split will be always the same\n",
    "\n",
    "# Look at the objects the split returned...\n",
    "\n",
    "# Xtrain\n",
    "print(\"\\n\")\n",
    "print(\"Xtrain:\", Xtrain, type(Xtrain), Xtrain.shape, len(Xtrain))\n",
    "\n",
    "# Xtest\n",
    "print(\"\\n\")\n",
    "print(\"Xtest\", Xtest, type(Xtest), Xtest.shape, len(Xtest))\n",
    "\n",
    "# ytrain\n",
    "print(\"\\n\")\n",
    "print(\"ytrain\", ytrain, type(ytrain), ytrain.shape, len(ytrain))\n",
    "\n",
    "# ytest:\n",
    "print(\"\\n\")\n",
    "print(\"ytest\", ytest, type(ytest), ytest.shape, len(ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the split is 75% train and 25% test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "('[Training] Accuracy score: (y_predict_training,ytrain)', 0.85194725544311556)\n",
      "\n",
      "\n",
      "('[Test] Accuracy score (y_predict_test, ytest):', 0.84765409383624657)\n"
     ]
    }
   ],
   "source": [
    "# Construct the Logistic Regression model\n",
    "clf = LogisticRegression()\n",
    "\n",
    "# Fit the model on the training data\n",
    "clf.fit(Xtrain, ytrain) \n",
    "\n",
    "# Print the training score\n",
    "y_predict_training = clf.predict(Xtrain)\n",
    "print(\"\\n\")\n",
    "print(\"[Training] Accuracy score: (y_predict_training,ytrain)\",accuracy_score(y_predict_training,ytrain))\n",
    "\n",
    "# Print the accuracy from the testing data\n",
    "y_predict_test = clf.predict(Xtest)\n",
    "print(\"\\n\")\n",
    "print(\"[Test] Accuracy score (y_predict_test, ytest):\",accuracy_score(y_predict_test, ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Training accuracy: The model's training accuracy is pretty good at 85.1947%, which indicates there is no bias in the model.\n",
    "\n",
    "Test accuracy: The test accuracy and the training accuracy have fairly close scores, so there is no variance between the two. This is good because it indicates the model will generalize well. Meaning when new data is presented, the model will perform similarly.\n",
    "\n",
    "The lack of bias and variance are two desirable and important characteristics. Classification accuracy is best used when treating the entire population. It weights all errors equally and lumps them into one group. The issue is there may be different tolerances for different errors. For example, if Threads wanted to be sure to reach *all* customers who are predicted to respond to the promotion (no Type I errors), and they did not mind sending the promotion to \"extra\" customers who will not respond (some Type II errors) then we will want to look at other metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training Classification Report:]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.98      0.92     13615\n",
      "          1       0.66      0.21      0.32      2690\n",
      "\n",
      "avg / total       0.83      0.85      0.82     16305\n",
      "\n",
      "[Test Classification Report:]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.98      0.91      4514\n",
      "          1       0.65      0.21      0.32       921\n",
      "\n",
      "avg / total       0.82      0.85      0.81      5435\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# More comprehensive performance analysis\n",
    "\n",
    "print(\"[Training Classification Report:]\")\n",
    "print(classification_report(ytrain, y_predict_training))\n",
    "\n",
    "print(\"[Test Classification Report:]\")\n",
    "print(classification_report(ytest, y_predict_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision: Precision is the number of true positive results divided by the number of total (true and false) positive results. It measures the quality of the classification.\n",
    "\n",
    "Recall: Recall is the number of true positive results divided by the true positives and false negatives (items that should've been in the positive class, but were not). This is a measure of completeness.\n",
    "\n",
    "f1 Score: The F1 score is a weighted average of the precision and recall. An F1 score reaches its best value at 1 and worst score at 0.\n",
    "\n",
    "Support: The number of occurences in each class.\n",
    "\n",
    "The results are similar between the training and test sets, so we will focus on the test data metrics. For the test data, the precision is 86% for the Non-Responsive customers and 65% for the Responsive customers. The recall is 98% for the Non-Responsive customers and only **21% for the Responsive customers, meaning it is missing many of the customers who should be marked as responsive**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Tuning the Logistic Regression Model\n",
    "\n",
    "We will now tune some hyperparameters to hopefully improve performance. We will use cross-validation. In Logistic Regression, the most important parameter to tune is the regularization parameter C. The regularization parameter is used to control for unlikely high regression coefficients, and in other cases can be used when data is sparse, as a method of feature selection.\n",
    "\n",
    "We use the following cv_score function to perform K-fold cross-validation and apply a scoring function to each test fold. In this incarnation we use accuracy score as the default scoring function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cv_score(clf, x, y, score_func=accuracy_score):\n",
    "    result = 0\n",
    "    nfold = 5\n",
    "    for train, test in KFold(nfold).split(x): # split data into train/test groups, 5 times\n",
    "        clf.fit(x[train], y[train]) # fit\n",
    "        result += score_func(clf.predict(x[test]), y[test]) # evaluate score function on held-out data\n",
    "    return result / nfold # average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example of using the cv_score function for a basic logistic regression model without regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.851456608402\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "score = cv_score(clf, Xtrain, ytrain)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a list of C values. For each value of C, we will use the training set to create a logistic regression model and find the average score for the model. We will then pick the C with the highest average score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.851824593683 10\n"
     ]
    }
   ],
   "source": [
    "# The list of C values\n",
    "Cs = [0.001, 0.1, 1, 10, 100]\n",
    "\n",
    "max_score = 0\n",
    "\n",
    "for C in Cs:\n",
    "        clf = LogisticRegression(C=C)\n",
    "        score = cv_score(clf, Xtrain, ytrain)\n",
    "\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            best_C = C\n",
    "print max_score, best_C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will test on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84783808647654091"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfl = LogisticRegression(C=best_C)\n",
    "clfl.fit(Xtrain, ytrain)\n",
    "ypred = clfl.predict(Xtest)\n",
    "accuracy_score(ypred, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the Classification Report with the \"best\" C value (C=10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test Classification Report with C=10:]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.98      0.91      4514\n",
      "          1       0.66      0.21      0.32       921\n",
      "\n",
      "avg / total       0.82      0.85      0.81      5435\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"[Test Classification Report with C=10:]\")\n",
    "print(classification_report(ytest, ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Classification Report shows the metrics improved very little. Most importantly, the Recall for the '1' or Responsive group did not improve at all. The Recall score will most likely not improve much more with further tuning because there is a large imbalance in the size of the groups. It is difficult to capture all of the responsive customers when there is such a small number within the dataset.\n",
    "\n",
    "We will now move on to Random Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84250229990800363"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Random Forest model\n",
    "rfCLF = RandomForestClassifier()\n",
    "# Train the Random Forest model on training data\n",
    "rfCLF.fit(Xtrain, ytrain.ravel())\n",
    "\n",
    "# Test Random Forest model on the test data\n",
    "ypredRF = rfCLF.predict(Xtest)\n",
    "accuracy_score(ypredRF, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test Classification Report from Random Forest:]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.97      0.91      4514\n",
      "          1       0.60      0.20      0.31       921\n",
      "\n",
      "avg / total       0.81      0.84      0.81      5435\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"[Test Classification Report from Random Forest:]\")\n",
    "print(classification_report(ytest, ypredRF))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The Random Forest Classification Report shows a slight decline in the Recall for the Non-Responsive group, and the Precision for the Responsive group. The Recall for the Responsive customers increased by two percentage points. We will now tune the model to see if we can gain more improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning the Random Forest Model\n",
    "\n",
    "We will now tune the hyperparameters for the Random Forest Model. There are many parameters to choose from, so we will use Scikit-Learnâ€™s GridSearchCV method to evaluate combinations from the grid defined below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the parameter grid \n",
    "param_grid = {\n",
    "    'n_estimators': [200, 300, 400],\n",
    "    'max_features': [None, 'sqrt', 'log2'],\n",
    "    'max_depth': [None, 50, 100, 150]\n",
    "}\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rfCLF, param_grid = param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit the grid search to the data\n",
    "#grid_search.fit(Xtrain, ytrain.ravel())\n",
    "#grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85243790248390061"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-create the model with the \"best\" parameters of 'max_depth'=None,'max_features'=None,'n_estimators'=200\n",
    "rfCLF1 = RandomForestClassifier(n_estimators=200,max_features=None,max_depth=None)\n",
    "# Train the updated Random Forest model on training data\n",
    "rfCLF1.fit(Xtrain, ytrain.ravel())\n",
    "\n",
    "# Test updated Random Forest model on the test data\n",
    "ypredRF1 = rfCLF1.predict(Xtest)\n",
    "accuracy_score(ypredRF1, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test Classification Report from Updated Random Forest:]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.97      0.92      4514\n",
      "          1       0.64      0.30      0.40       921\n",
      "\n",
      "avg / total       0.83      0.85      0.83      5435\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"[Test Classification Report from Updated Random Forest:]\")\n",
    "print(classification_report(ytest, ypredRF1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Classification Report for the tuned model looks better, but the Responsive Recall is still very low at 30%. The imbalanced classes make it difficult for the model to accurately capture the Responsive group. The Responsive group is too small (16-17% of the total dataset). We will now move to Resampling to try and compensate for the imbalance and improve the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Resampling\n",
    "\n",
    "Resampling attempts to balance the class size. Oversampling randomly replicates the minority class to increase the population. Undersampling randomly reduces the majority class to decrease the population size. There are arguments for both methods. We will perform both Logistic Regression and Random Forest on an Oversampled dataset and an Undersampled dataset to compare the results.\n",
    "\n",
    "#### Oversampling\n",
    "\n",
    "We will oversample using the SMOTE (Synthetic Minority Oversampling Technique) algorithm. SMOTE finds the k-nearest neighbors of the minority dataset and uses those to create random similar observations. Oversampling can be done before or after the train/test split. The concern with oversampling before the split is \"bleeding\" the synthetic data into the test set. This would train the model to better predict the test set than a new dataset. For this reason, we will perform the oversampling after the train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({0: 13615, 1: 13615})\n"
     ]
    }
   ],
   "source": [
    "# Oversampling with SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "X_Ores, y_Ores = sm.fit_sample(Xtrain, ytrain)\n",
    "print('Resampled dataset shape {}'.format(Counter(y_Ores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "('[Training] Accuracy score: (y_predict_trainingLRO,y_Ores)', 0.77238340066103561)\n",
      "\n",
      "\n",
      "('[Test] Accuracy score (y_predict_testLRO, y_Ores):', 0.7243790248390064)\n"
     ]
    }
   ],
   "source": [
    "# Oversampled data with Logistic Regression\n",
    "clfO = LogisticRegression()\n",
    "\n",
    "# Fit the model on the training data\n",
    "clfO.fit(X_Ores, y_Ores) \n",
    "\n",
    "# Print the training score\n",
    "y_predict_trainingLRO = clfO.predict(X_Ores)\n",
    "print(\"\\n\")\n",
    "print(\"[Training] Accuracy score: (y_predict_trainingLRO,y_Ores)\",accuracy_score(y_predict_trainingLRO,y_Ores))\n",
    "\n",
    "# Print the accuracy from the testing data\n",
    "y_predict_testLRO = clfO.predict(Xtest)\n",
    "print(\"\\n\")\n",
    "print(\"[Test] Accuracy score (y_predict_testLRO, y_Ores):\",accuracy_score(y_predict_testLRO, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training Classification Report:]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.70      0.75     13615\n",
      "          1       0.74      0.84      0.79     13615\n",
      "\n",
      "avg / total       0.78      0.77      0.77     27230\n",
      "\n",
      "[Test Classification Report:]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.70      0.81      4514\n",
      "          1       0.36      0.82      0.50       921\n",
      "\n",
      "avg / total       0.85      0.72      0.76      5435\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# More comprehensive performance analysis of Oversampled Logistic Regression Model\n",
    "\n",
    "print(\"[Training Classification Report:]\")\n",
    "print(classification_report(y_Ores, y_predict_trainingLRO))\n",
    "\n",
    "print(\"[Test Classification Report:]\")\n",
    "print(classification_report(ytest, y_predict_testLRO))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Test Classification Report shows improved percentages for the precision of the non-responsive group and the recall of the responsive group, but decreased percentages for the recall for the non-responsive group and the precision of the responsive group.\n",
    "\n",
    "Precision is measuring how many of the predictions the model made correctly. The precision for the non-responsive group is high at 95%. The precision for the non-responsive group is low at 36% - there were many false positives for the non-responsive group.\n",
    "\n",
    "The recall is looking at how many positive cases the model missed. The non-responsive group recall is 70%; 30% of the positive results are being missed. The responsive group recall is 82%. This is a large improvement from the previous models.\n",
    "\n",
    "We will now tune the regularization parameter C to test if it improves the model. For each value of C, we will use the training set to create a logistic regression model and find the average score for the model. We will then pick the C with the highest average score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.677157546823 10\n"
     ]
    }
   ],
   "source": [
    "# The list of C values\n",
    "Cs = [0.001, 0.1, 1, 10, 100]\n",
    "\n",
    "max_score = 0\n",
    "\n",
    "for C in Cs:\n",
    "        clfLROR = LogisticRegression(C=C)\n",
    "        score = cv_score(clfLROR, X_Ores, y_Ores)\n",
    "\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            best_C = C\n",
    "print max_score, best_C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now test the C with the highest average score on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72419503219871206"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clflLROR = LogisticRegression(C=best_C)\n",
    "clflLROR.fit(X_Ores, y_Ores)\n",
    "ypredLROR = clflLROR.predict(Xtest)\n",
    "accuracy_score(ypredLROR, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification Report with the \"best\" value of C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test Classification Report with C=10:]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.70      0.81      4514\n",
      "          1       0.36      0.82      0.50       921\n",
      "\n",
      "avg / total       0.85      0.72      0.76      5435\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"[Test Classification Report with C=10:]\")\n",
    "print(classification_report(ytest, ypredLROR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no change in the metrics with the Logistic Regression hyper-parameterization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81968721251149956"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Oversampled data with Random Forest Model\n",
    "OrfCLF = RandomForestClassifier()\n",
    "\n",
    "# Train the Random Forest model on oversampled training data\n",
    "OrfCLF.fit(X_Ores, y_Ores)\n",
    "\n",
    "# Test Random Forest model on the test data\n",
    "ypredORF = OrfCLF.predict(Xtest)\n",
    "accuracy_score(ypredORF, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test Classification Report from Random Forest:]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.92      0.89      4514\n",
      "          1       0.46      0.34      0.39       921\n",
      "\n",
      "avg / total       0.80      0.82      0.81      5435\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report for oversampled Random Forest Model\n",
    "print(\"[Test Classification Report from Random Forest:]\")\n",
    "print(classification_report(ytest, ypredORF))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest model using the oversampled data favors the non-responsive group. The precision and recall for the non-responsive group are 87% and 97%, respectively. The responsive group precision and recall are 48% and 35%, respectively. It seems that the model is just marking most as non-responsive. We will now tune the model to see if we can improve the metrics.\n",
    "\n",
    "### Tune Oversampled Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use the same parameter grid \n",
    "param_grid = {\n",
    "    'n_estimators': [200, 300, 400],\n",
    "    'max_features': [None, 'sqrt', 'log2'],\n",
    "    'max_depth': [None, 50, 100, 150]\n",
    "}\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_searchO = GridSearchCV(estimator = OrfCLF, param_grid = param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit the grid search to the oversampled data\n",
    "#grid_searchO.fit(X_Ores, y_Ores.ravel())\n",
    "#grid_searchO.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82999080036798523"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-create the model with the \"best\" parameters of 'max_depth'=None,'max_features'=None,'n_estimators'=200\n",
    "OrfCLF1 = RandomForestClassifier(n_estimators=400,max_features='log2',max_depth=50)\n",
    "# Train the updated Random Forest model on oversampled training data\n",
    "OrfCLF1.fit(X_Ores, y_Ores.ravel())\n",
    "\n",
    "# Test updated Random Forest model on the test data\n",
    "ypredORF1 = OrfCLF1.predict(Xtest)\n",
    "accuracy_score(ypredORF1, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test Classification Report from Updated Random Forest:]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.92      0.90      4514\n",
      "          1       0.50      0.41      0.45       921\n",
      "\n",
      "avg / total       0.82      0.83      0.82      5435\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"[Test Classification Report from Updated Random Forest:]\")\n",
    "print(classification_report(ytest, ypredORF1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undersampling\n",
    "\n",
    "We will undersample using the Random Undersampling technique. Random Undersampling seeks to balance the classes by randomly eliminating observations from the majority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({0: 2690, 1: 2690})\n"
     ]
    }
   ],
   "source": [
    "# Undersampling by \"Random Undersampling\"\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_Ures, y_Ures = rus.fit_sample(Xtrain, ytrain)\n",
    "print('Resampled dataset shape {}'.format(Counter(y_Ures)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "('[Training] Accuracy score: (y_predict_trainingLRU,y_Ures)', 0.77286245353159855)\n",
      "\n",
      "\n",
      "('[Test] Accuracy score (y_predict_testLRU, y_Ures):', 0.71720331186752528)\n"
     ]
    }
   ],
   "source": [
    "# Undersampled data with Logistic Regression\n",
    "clfU = LogisticRegression()\n",
    "\n",
    "# Fit the model on the training data\n",
    "clfU.fit(X_Ures, y_Ures) \n",
    "\n",
    "# Print the training score\n",
    "y_predict_trainingLRU = clfU.predict(X_Ures)\n",
    "print(\"\\n\")\n",
    "print(\"[Training] Accuracy score: (y_predict_trainingLRU,y_Ures)\",accuracy_score(y_predict_trainingLRU,y_Ures))\n",
    "\n",
    "# Print the accuracy from the testing data\n",
    "y_predict_testLRU = clfU.predict(Xtest)\n",
    "print(\"\\n\")\n",
    "print(\"[Test] Accuracy score (y_predict_testLRU, y_Ures):\",accuracy_score(y_predict_testLRU, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training Classification Report:]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.70      0.76      2690\n",
      "          1       0.74      0.84      0.79      2690\n",
      "\n",
      "avg / total       0.78      0.77      0.77      5380\n",
      "\n",
      "[Test Classification Report:]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.69      0.80      4514\n",
      "          1       0.36      0.84      0.50       921\n",
      "\n",
      "avg / total       0.85      0.72      0.75      5435\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# More comprehensive performance analysis of Undersampled Logistic Regression Model\n",
    "\n",
    "print(\"[Training Classification Report:]\")\n",
    "print(classification_report(y_Ures, y_predict_trainingLRU))\n",
    "\n",
    "print(\"[Test Classification Report:]\")\n",
    "print(classification_report(ytest, y_predict_testLRU))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metrics for the Logistic Regression model using undersampled data are fairly close to the Logistic Regression model using oversampled data. The precision for the non-responsive group is very good at 95%, while the precision in the responsive group is fairly poor at 36%. The model is accurately predicting most of the non-responsive group, but the responsive group is getting a lot of false positives.\n",
    "\n",
    "The recall for the non-responsive group is not very good at 69%. The model is missing over 30% of the positive results for the non-responsive group. The recall for the responsive group is fairly good at 84%. The model is only missing 15%  of the positive results.\n",
    "\n",
    "We will now tune the regularization parameter C to test if it improves the model. For each value of C, we will use the training set to create a logistic regression model and find the average score for the model. We will then pick the C with the highest average score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.660037174721 100\n"
     ]
    }
   ],
   "source": [
    "# The list of C values\n",
    "Cs = [0.001, 0.1, 1, 10, 100]\n",
    "\n",
    "max_score = 0\n",
    "\n",
    "for C in Cs:\n",
    "        clfLRUR = LogisticRegression(C=C)\n",
    "        score = cv_score(clfLRUR, X_Ures, y_Ures)\n",
    "\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            best_C = C\n",
    "print max_score, best_C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now test the C with the highest average score on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71609935602575892"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clflLRUR = LogisticRegression(C=best_C)\n",
    "clflLRUR.fit(X_Ures, y_Ures)\n",
    "ypredLRUR = clflLRUR.predict(Xtest)\n",
    "accuracy_score(ypredLRUR, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification Report with the \"best\" value of C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test Classification Report with C=100:]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.69      0.80      4514\n",
      "          1       0.36      0.83      0.50       921\n",
      "\n",
      "avg / total       0.85      0.72      0.75      5435\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"[Test Classification Report with C=100:]\")\n",
    "print(classification_report(ytest, ypredLRUR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74829806807727695"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Undersampled data with Random Forest Model\n",
    "UrfCLF = RandomForestClassifier()\n",
    "\n",
    "# Train the Random Forest model on undersampled training data\n",
    "UrfCLF.fit(X_Ures, y_Ures)\n",
    "\n",
    "# Test Random Forest model on the test data\n",
    "ypredURF = UrfCLF.predict(Xtest)\n",
    "accuracy_score(ypredURF, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test Classification Report from Random Forest:]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.76      0.83      4514\n",
      "          1       0.37      0.68      0.48       921\n",
      "\n",
      "avg / total       0.83      0.75      0.77      5435\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report for undersampled Random Forest Model\n",
    "print(\"[Test Classification Report from Random Forest:]\")\n",
    "print(classification_report(ytest, ypredURF))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Random Forest model using the undersampled data is not the strongest model. The recall for the non-responsive group is 76%, and the recall for the responsive group is 69%. The recall for the responsive group is better than other models, but still not great. The precision for the non-responsive group is 92% (great!) and the precision for the responsive group is 37% (no good). We will now tune the model to see if we can improve the metrics.\n",
    "\n",
    "### Tune Undersampled Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use the same parameter grid \n",
    "param_grid = {\n",
    "    'n_estimators': [200, 300, 400],\n",
    "    'max_features': [None, 'sqrt', 'log2'],\n",
    "    'max_depth': [None, 50, 100, 150]\n",
    "}\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_searchU = GridSearchCV(estimator = UrfCLF, param_grid = param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit the grid search to the undersampled data\n",
    "#grid_searchU.fit(X_Ures, y_Ures.ravel())\n",
    "#grid_searchU.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73781048758049683"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-create the model with the \"best\" parameters of 'max_depth'=None,'max_features'=None,'n_estimators'=200\n",
    "UrfCLF1 = RandomForestClassifier(n_estimators=300,max_features=None,max_depth=100)\n",
    "# Train the updated Random Forest model on undersampled training data\n",
    "UrfCLF1.fit(X_Ures, y_Ures.ravel())\n",
    "\n",
    "# Test updated Random Forest model on the test data\n",
    "ypredURF1 = UrfCLF1.predict(Xtest)\n",
    "accuracy_score(ypredURF1, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test Classification Report from Updated Random Forest:]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.72      0.82      4514\n",
      "          1       0.37      0.82      0.51       921\n",
      "\n",
      "avg / total       0.85      0.74      0.77      5435\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"[Test Classification Report from Updated Random Forest:]\")\n",
    "print(classification_report(ytest, ypredURF1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noaKioqKSK6qjUFFRUVHJlf8Hq5ml5Rl/BMsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a11e8dc90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculate the fpr and tpr for all thresholds of the classification and plot\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Logistic Regression\n",
    "fpr, tpr, threshold = metrics.roc_curve(ytest, y_predict_test)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, 'blue', label = 'Log Reg AUC = %0.2f' % roc_auc)\n",
    "\n",
    "# Logistic Regression with Hyperparameterization\n",
    "fpr, tpr, threshold = metrics.roc_curve(ytest, ypred)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, 'green', label = 'Log Reg w/ Hyp AUC = %0.2f' % roc_auc)\n",
    "\n",
    "# Random Forest\n",
    "fpr, tpr, threshold = metrics.roc_curve(ytest, ypredRF)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, 'purple', label = 'Rand For AUC = %0.2f' % roc_auc)\n",
    "\n",
    "# Random Forest with Hyperparameterization\n",
    "fpr, tpr, threshold = metrics.roc_curve(ytest, ypredRF1)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, 'red', label = 'Rand For w/ Hyp AUC = %0.2f' % roc_auc)\n",
    "\n",
    "### Oversampled Data\n",
    "\n",
    "# Logistic Regression (Oversampled)\n",
    "fpr, tpr, threshold = metrics.roc_curve(ytest, y_predict_testLRO)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, 'brown', label = 'Over Log Reg AUC = %0.2f' % roc_auc)\n",
    "\n",
    "# Logistic Regression with Hyperparameterization (Oversampled)\n",
    "fpr, tpr, threshold = metrics.roc_curve(ytest, ypredLROR)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, 'aqua', label = 'Over Log Reg w/ Hyp AUC = %0.2f' % roc_auc)\n",
    "\n",
    "# Random Forest (Oversampled)\n",
    "fpr, tpr, threshold = metrics.roc_curve(ytest, ypredORF)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, 'pink', label = 'Over Rand For AUC = %0.2f' % roc_auc)\n",
    "\n",
    "# Random Forest with Hyperparameterization (Oversampled)\n",
    "fpr, tpr, threshold = metrics.roc_curve(ytest, ypredORF1)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, 'tan', label = 'Over Rand For w/ Hyp AUC = %0.2f' % roc_auc)\n",
    "\n",
    "### Undersampled Data\n",
    "\n",
    "# Logistic Regression (Undersampled)\n",
    "fpr, tpr, threshold = metrics.roc_curve(ytest, y_predict_testLRU)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, 'deepskyblue', label = 'Under Log Reg AUC = %0.2f' % roc_auc)\n",
    "\n",
    "# Logistic Regression with Hyperparameterization (Undersampled)\n",
    "fpr, tpr, threshold = metrics.roc_curve(ytest, ypredLRUR)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, 'orange', label = 'Under Log Reg w/ Hyp AUC = %0.2f' % roc_auc)\n",
    "\n",
    "# Random Forest (Undersampled)\n",
    "fpr, tpr, threshold = metrics.roc_curve(ytest, ypredURF)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, 'yellow', label = 'Under Rand For AUC = %0.2f' % roc_auc)\n",
    "\n",
    "# Random Forest with Hyperparameterization (Undersampled)\n",
    "fpr, tpr, threshold = metrics.roc_curve(ytest, ypredURF1)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, 'fuchsia', label = 'Under Rand For w/ Hyp AUC = %0.2f' % roc_auc)\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "\n",
    "# save plot to word doc for report\n",
    "plt.savefig('/Users/Molfer/Documents/Lisa/Springboard/Capstone 1/DataClothing/Images/ROC.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Client's needs will have a large impact on which model to choose. While all clients will want to be conscious of how they spend their money, each client will have a different comfort level with the proportions of True Positive and False Positive results. In this case, Threads is a large clothing store that presumably has a larger budget. They may be more comfortable with a larger False Positive rate than a small nonprofit. With this in mind, we will proceed with the Logistic Regression with Hyperparameterization model from the Oversampled test run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clfO.fit(X_Ores / np.std(X_Ores, 0), y_Ores)\n",
    "\n",
    "features = pd.DataFrame(clfO.coef_)\n",
    "\n",
    "features = pd.DataFrame(features.unstack())\n",
    "\n",
    "features.columns = ['value']\n",
    "\n",
    "features.reset_index(level=1,drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurenames = pd.DataFrame(list(clothingFileLRnoRESP))\n",
    "featurenames.columns = ['feature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    feature     value\n",
      "0  ZIP_CODE  0.026575\n",
      "1       REC -0.024648\n",
      "2       FRE  0.739203\n",
      "3       MON  0.329757\n",
      "4   CC_CARD  0.050173\n"
     ]
    }
   ],
   "source": [
    "importance = pd.merge(featurenames, features, left_index=True, right_index=True)\n",
    "print(importance.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         feature     value  absvalue\n",
      "46      LTFREDAY -2.925280  2.925280\n",
      "2            FRE  0.739203  0.739203\n",
      "33       FREDAYS  0.530942  0.530942\n",
      "24       CCSPEND -0.356145  0.356145\n",
      "23       PSSPEND -0.333949  0.333949\n",
      "3            MON  0.329757  0.329757\n",
      "32          DAYS  0.290191  0.290191\n",
      "43     RESPONDED -0.263444  0.263444\n",
      "37        STYLES  0.195777  0.195777\n",
      "44  RESPONSERATE  0.182652  0.182652\n",
      "35       CLASSES -0.157704  0.157704\n",
      "95   CLUSTYPE_47 -0.147341  0.147341\n"
     ]
    }
   ],
   "source": [
    "importance['absvalue'] = importance['value'].abs()\n",
    "\n",
    "importanceSorted = importance.sort_values(by='absvalue',ascending=False)\n",
    "print(importanceSorted.head(12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Features\n",
    "\n",
    "- 'LTFREDAY' - Lifetime average time between visits\n",
    "- 'FRE' - Number of purchase visits\n",
    "- 'FREDAYS' - Number of days between purchases\n",
    "- 'CCSPEND' - Spending at the CC store\n",
    "- 'PSSPEND' - Spending at the PS store\n",
    "- 'MON' - Total net sales\n",
    "- 'DAYS' - Number of days the customer has been on file\n",
    "- 'RESPONDED' - Number of promotions responded to in the past year\n",
    "- 'STYLES' - Total number of individual items purchased by the customer\n",
    "- 'RESPONSERATE' - Promotion response rate for the past year - indicates which customers have ever responded to a marketing promotion before\n",
    "- 'CLASSES' - Number of different product classes purchased\n",
    "- 'CLUSTYPE' - Microvision lifestyle cluster type\n",
    "\n",
    "The most important feature in the chosen Logistic Regression model is the 'Lifetime average time between visits'. The feature is a negative indicator, meaning as the average time between visits increases, the likelihood of the customer responding to the promotion goes down. The next six important features in the model have to do with the number of purchase visits, days the customer has been on file or spending amounts, including spending at individual stores. The four features after that are the customer's response to other promotions, the number of total products purchased, and the number of product classes the customer has purchased.\n",
    "\n",
    "To increase customers response to promotions, I would set thresholds for each of these categories and target customers who met the thresholds. I would also identify which categories Threads would want to try and influence to expand the number of responsive customers. Threads ultimately wants increase the customers' rate of response to promotions to encourage customers to spend more money. The most important features that do not have to do directly with spending, (the category we want to increase) are customer visits and the number of different product classes purchased. I would work with Threads to identify ways to increase these metrics as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
